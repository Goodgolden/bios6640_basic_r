---
title: "Reading web data: Part I"
output:
  html_document: 
    toc: true
    toc_float: true
---
  
Today we will cover **web scraping** in the second of two lectures on **reading data from the web**. The first lecture covered APIs.

* We will use `tidyverse` syntax

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

library(tidyverse)
theme_set(theme_bw() + theme(legend.position = "bottom"))
```

## New software

Install these packages and Selector Gadget now if you haven't already!

* `rvest`
* `httr`
* `janitor`
* `stringr`
* [Selector Gadget](http://selectorgadget.com). 


```{r, message = FALSE}
library(tidyverse)
library(rvest)
library(httr)
library(janitor)
```


## Extracting tables

[This page](http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm) contains data from the National Survey on Drug Use and Health; it includes tables for drug use in the past year or month, separately for specific kinds of drug use. These data are potentially useful for analysis, and we'd like to be able to read in the first table. 

First, let's make sure we can load the data from the web. 

```{r}
url = "http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm"

drug_use_xml = read_html(url)
drug_use_xml
```

Doesn't look like much, but we're there. Rather than trying to grab something using a CSS selector, let's try our luck extracting the tables from the HTML. Below extracts the tables from the html document.

```{r}
drug_use_xml %>%
  html_nodes(css = "table")
```

This has extracted _all_ of the tables on the original page; that's why we have a list with 15 elements. (In case you haven't really talked about lists yet, you can think of them as a general collection of objects in R.) 

We're only focused on the first table for now, so let's get the contents from the first list element, and then we'll convert it into an `R` dataframe.

```{r}
table_marj = (drug_use_xml %>% html_nodes(css = "table"))[[1]] # extracts the first element of the list, which is the first table

table_marj = table_marj %>% html_table() 
```

I won't print the table here, but if you look at it you'll notice a problem: the "note" at the bottom of the table appears in every column in the first row. We need to remove that; I'll also convert to a tibble so that things print nicely.

```{r}
table_marj = table_marj %>%
  slice(-1) %>%  
  as_tibble()

table_marj
```

Success!!

### Colorado mountains 

Now we'll try another example. [This page]() on Wikipedia has a table of the tallest mountains in Colorado. Let's extract that table.

```{r}
url = "https://en.wikipedia.org/wiki/List_of_the_highest_major_summits_of_Colorado"

peaks = (read_html(url) %>% html_nodes(css = "table"))[[1]] %>% 
  html_table() %>% as_tibble()

peaks
```

This doesn't seem like what we want... what happened?

```{r}
peaks = (read_html(url) %>% html_nodes(css = "table"))[[2]] %>% 
  html_table() %>% as_tibble()

peaks
```

That's better. I'm going to do a little data cleaning to get the data in a tidier format. In particular, I want:

* lower case column names without spaces
* elevation to be a numeric variable

Really I would want all of the variables to be tidier but I'll just show you how to clean one.

```{r}
peaks %>% janitor::clean_names() %>%
  mutate(elevation = str_remove(elevation, ",")) %>%
  separate(elevation, into = c("elevation_ft", "units"), extra = "drop") %>%
  mutate(elevation_ft = as.numeric(elevation_ft)) %>%
  select(-units)
```


### Practice problem

**_Learning assessment:_** Create a data frame that contains the cost of living table comparing Denver, Colorado to New York City from [this page](https://www.bestplaces.net/cost-of-living/denver-co/new-york-ny/50000).

<details>
<summary> Solution </summary>

The code below shows one approach to this data cleaning process:

```{r, eval = FALSE}
nyc_cost = 
  read_html("https://www.bestplaces.net/cost-of-living/denver-co/new-york-ny/50000") %>%
  html_nodes(css = "table") %>%
  .[[1]] %>%
  html_table(header = TRUE)
```

Denver is cheaper than NYC, but still much more expensive than the national average.

</details>

## CSS Selectors

Suppose we'd like to scrape the data about the [Harry Potter Saga](https://www.imdb.com/list/ls000630791/) from the IMDB page. The first step is the same as before -- we need to get the HTML.

```{r}
hpsaga_html = 
  read_html("https://www.imdb.com/list/ls000630791/")
```

### Selector Gadget

Run this code: `vignette("selectorgadget")` if you need a refresher on how to use the Selector Gadget.

The information isn't stored in a handy table, so we're going to isolate the CSS selector for elements we care about. A bit of clicking around gets me something like below. 

<img src="read_from_web_css_selctor.png" style="width:75%">
  
For each element, I'll use the CSS selector in `html_nodes()` to extract the relevant HTML code, and convert it to text. Then I can combine these into a data frame. 

```{r}
title_vec = 
  hpsaga_html %>%
  html_nodes(".lister-item-header a") %>%
  html_text()

gross_rev_vec = 
  hpsaga_html %>%
  html_nodes(".text-muted .ghost~ .text-muted+ span") %>%
  html_text()

runtime_vec = 
  hpsaga_html %>%
  html_nodes(".runtime") %>%
  html_text()

hpsaga_df = 
  tibble(
    title = title_vec,
    revenue = gross_rev_vec,
    runtime = runtime_vec)
```


### Yelp: Top Denver Restaurants

```{r}
yelp_html = 
  read_html("https://www.yelp.com/search?find_desc=Restaurants&find_loc=Denver%2C+CO")


restaurants = yelp_html %>%
  html_nodes(".text-color--black-regular__373c0__38bRH.text-size--inherit__373c0__2gFQ3") %>%
  html_text()


num_reviews = yelp_html %>%
  html_nodes(".reviewCount__373c0__2r4xT") %>%
  html_text()


tibble(restaurants = restaurants,
       num_reviews = num_reviews) %>%
  slice(-1) %>%
  mutate(num_reviews = str_remove(num_reviews, " reviews"),
         num_reviews = str_remove(num_reviews, " review"),
         num_reviews = as.numeric(num_reviews)) 

```


### Practice problem

**_Learning Assessment:_** [This page](https://www.amazon.com/product-reviews/B00005JNBQ/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=avp_only_reviews&sortBy=recent&pageNumber=1) contains the 10 most recent reviews of the movie "Napoleon Dynamite". Use a process similar to the one above to extract the titles of the reviews. Note: getting the star ratings from Amazon is trickier, but the CSS path `"#cm_cr-review_list .review-rating"` helps -- I discovered this after about an hour of googling around. 

<details>
<summary> Solution </summary>

The code below will give me relevant information for the ten most recent reviews on Amazon:

```{r, eval = FALSE}
url = "https://www.amazon.com/product-reviews/B00005JNBQ/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=avp_only_reviews&sortBy=recent&pageNumber=1"
dynamite_html = read_html(url)

review_titles = 
  dynamite_html %>%
  html_nodes(".a-text-bold span") %>%
  html_text()

review_stars = 
  dynamite_html %>%
  html_nodes("#cm_cr-review_list .review-rating") %>%
  html_text()

review_text = 
  dynamite_html %>%
  html_nodes(".review-text-content span") %>%
  html_text()

reviews = tibble(
  title = review_titles,
  stars = review_stars,
  text = review_text
)
```

</details>


## Other materials

* Much of this material came from [Jeff Goldsmith's Data Science I class](https://p8105.com/). Check it out for more cool stuff!
* A recent short course presented similar topics to those above; a GitHub repo for the course is [here](https://github.com/ropensci/user2016-tutorial)
* There are some cool projects based on scraped data; the RStudio community collected some [here](https://community.rstudio.com/t/whats-the-most-interesting-use-of-rvest-youve-seen-in-the-wild/745)

